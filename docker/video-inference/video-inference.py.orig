import time
import random
import json
import matplotlib.image as mpimg
import boto3
import os
import uuid

origin_bucket = os.environ['origin_bucket']
input_prefix = os.environ['input_bucket_prefix']
output_bucket = os.environ['output_bucket']
output_prefix = os.environ['output_bucket_prefix']

class videoframe:
    def __init__(self, start_second, end_second):
        self.start_second = start_second
        self.end_second = end_second

#######################################################
def convert(seconds):
    seconds = seconds % (24 * 3600)
    hour = seconds // 3600
    seconds %= 3600
    minutes = seconds // 60
    seconds %= 60

    return "%02d:%02d:%02d;00" % (hour, minutes, seconds)

#######################################################
def visualize_detection(img_file, dets, thresh, img_height, img_width):
    SCALE_FACTOR = 1.89             #Scaling factor used to resize the bounding box from the inference image size
    
    bb_list = []
    overlapped_images = []

    for item in dets[0]:
        box_ids, scores, bboxes = item[0],item[1],item[2:]
        
        if scores > thresh:
            bb_list.append(bboxes)
        
    #bike rectangle
    bike_width = 0.65
    bike_height = 0.25
    bike_left = 0.13
    bike_top = 0.75

    bike_x1 = int(bike_left * img_width)
    bike_y1 = int(bike_top * img_height)
    bike_x2 = int(bike_left * img_width + bike_width * img_width)
    bike_y2 = int(bike_top * img_height + bike_height * img_height)

    for item in bb_list:
        xmin, ymin, xmax, ymax = item[0], item[1], item[2], item[3]

        xmin = int(xmin * SCALE_FACTOR)
        xmax = int(xmax * SCALE_FACTOR)
        ymin = int(ymin * SCALE_FACTOR)
        ymax = int(ymax * SCALE_FACTOR)

        if (xmax >= bike_x1 and bike_x2 >= xmin) and (ymax >= bike_y1 and bike_y2 >= ymin):
            overlapped_images.append(img_file)
            break                                 #We only care about the first collision

    return overlapped_images


#######################################################
def start_batch_transformation(model_name, s3_input_path, s3_output_path):
    timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())
    batch_job_name="vehicle-classification" + timestamp
    batch_input = s3_input_path
    request = \
    {
        "TransformJobName": batch_job_name,
        "ModelName": model_name,
        "MaxConcurrentTransforms": 25,
        "MaxPayloadInMB": 4,
        "BatchStrategy": "SingleRecord",
        "TransformOutput": {
            "S3OutputPath": s3_output_path
        },
        "TransformInput": {
            "DataSource": {
                "S3DataSource": {
                    "S3DataType": "S3Prefix",
                    "S3Uri": batch_input
                }
            },
            "ContentType": "application/x-image",
            "SplitType": "None",
            "CompressionType": "None"
        },
        "TransformResources": {
                "InstanceType": "ml.p3.2xlarge",
                "InstanceCount": 1
        }
    }
    sagemaker = boto3.client('sagemaker')
    sagemaker.create_transform_job(**request)

    return batch_job_name

#######################################################
def check_for_collisions(s3_input_bucket, s3_input_prefix, s3_output_bucket, s3_output_prefix):
    s3 = boto3.client('s3')
    response = s3.list_objects(Bucket=s3_input_bucket, Prefix=s3_input_prefix)

    threshold = .9

    overlapped_images = []

    height = 0
    width = 0
    
    for key in response['Contents']:
        file_name = key['Key']
        
        file_name1 = file_name.split("/")
        file_name_without_prefix = file_name1[len(file_name1) - 1]
        
        if height == 0 or width == 0:
            s3_stream = boto3.resource('s3')
            bucket = s3_stream.Bucket(s3_input_bucket)
            object = bucket.Object(file_name)
            
            with open('sample-img.jpg', 'wb') as data:
                object.download_fileobj(data)
            
            img=mpimg.imread('sample-img.jpg')
            height = img.shape[0]
            width = img.shape[1]
            

        key = s3_output_prefix + "/" + file_name_without_prefix + '.out'
        
        result = s3.get_object(Bucket=s3_input_bucket,Key=key)["Body"].read().decode('ascii')
        detections = json.loads(result)
        overlapped_images.append(visualize_detection(file_name, detections, threshold, height, width))

    return overlapped_images

#######################################################
def generate_clip_times(encounters):
    frame_list = []
    for item in encounters:
        if not item:
            continue

        #We've saved the frame rate as part of the file name, for ease of processing
        file_parts = item[0].split("_")

        frame_rate = file_parts[len(file_parts) - 2]
        frame_part = file_parts[len(file_parts) - 1]
        frame_num = frame_part.split(".")[0]
        beginning_sec = int(int(frame_num) / int(float(frame_rate)))

        frame_start_second = max(0, beginning_sec - 5)
        frame_end_second = beginning_sec + 5

        found_frame = False
        for frame in frame_list:
            if (frame.end_second >= frame_start_second and frame_end_second >= frame.start_second) :
                found_frame = True
                frame.start_second = max(0, min(frame.start_second, frame_start_second))
                frame.end_second = max(frame.end_second,frame_end_second)

        if found_frame == False:
            frame_list.append(videoframe(frame_start_second, frame_end_second))

    return frame_list

#######################################################
def process_media(input_bucket, input_file, output_bucket, frames):
    mediaconvert_endpoint_url="<MEDIACONVERT_ENDPOINT_URL>"
    client = boto3.client('mediaconvert', endpoint_url=mediaconvert_endpoint_url)

    jobs = []

    for item in frames:
        #Pass each item off to video encode

        response = client.create_job(
            Role="<MEDIACONVERT_SERVICE_ROLE>",
            Settings={
                "TimecodeConfig": {
                  "Source": "ZEROBASED"
                },
                "OutputGroups": [
                  {
                    "Name": "File Group",
                    "Outputs": [
                      {
                        "Preset": "System-Generic_Hd_Mp4_Avc_Aac_16x9_1920x1080p_60Hz_9Mbps",
                        "NameModifier": "-" + str(uuid.uuid4())
                      }
                    ],
                    "OutputGroupSettings": {
                      "Type": "FILE_GROUP_SETTINGS",
                      "FileGroupSettings": {
                        "Destination": "s3://" + output_bucket + "/"
                      }
                    }
                  }
                ],
                "AdAvailOffset": 0,
                "Inputs": [
                  {
                    "InputClippings": [
                      {
                        "EndTimecode": convert(item.end_second),
                        "StartTimecode": convert(item.start_second)
                      }
                    ],
                    "AudioSelectors": {
                      "Audio Selector 1": {
                        "Offset": 0,
                        "DefaultSelection": "DEFAULT",
                        "ProgramSelection": 1
                      }
                    },
                    "VideoSelector": {
                      "ColorSpace": "FOLLOW",
                      "Rotate": "AUTO",
                      "AlphaBehavior": "DISCARD"
                    },
                    "FilterEnable": "AUTO",
                    "PsiControl": "USE_PSI",
                    "FilterStrength": 0,
                    "DeblockFilter": "DISABLED",
                    "DenoiseFilter": "DISABLED",
                    "TimecodeSource": "ZEROBASED",
                    "FileInput": "s3://" + input_bucket + "/" + input_file
                  }
                ]
              })
        jobs.append(response)
    return jobs

#######################################################
def generate_final_videos(orig_file, output_bucket, jobs):
    mediaconvert_endpoint_url="<MEDIACONVERT_ENDPOINT_URL>"
    client = boto3.client('mediaconvert', endpoint_url=mediaconvert_endpoint_url)

    rendered_videos = []

    for item in jobs:
        name_modifier = item['Job']['Settings']['OutputGroups'][0]['Outputs'][0]['NameModifier']
        orig_file_parts = orig_file.split(".")
        rendered_videos.append(orig_file_parts[0] + name_modifier + '.' + str.lower(orig_file_parts[1]))

        job_id = item['Job']['Id']
        completed = False

        while(True):
            response = client.get_job(Id=job_id)
            job_status = response['Job']['Status']

            if job_status == 'COMPLETE':
                print('Job ' + job_id + ' completed!')
                break
            if job_status == 'ERROR':
                print('Job ' + job_id + ' errored out!')
                break

            print(job_status)
            time.sleep(30)

    return rendered_videos

#######################################################
def send_notifications(rendered_videos):
    #Start by pre-signing URLs
    s3 = boto3.client('s3')

    video_urls = []
    for item in rendered_videos:
        response = s3.generate_presigned_url('get_object', Params={'Bucket': output_bucket, 'Key': item}, ExpiresIn=86400)
        video_urls.append(response)

    sns = boto3.client('sns')

    message = 'We have detected ' + str(len(video_urls)) + ' incident'
    if len(video_urls) > 1:
        message = message + 's'

    message = message + '\n\nYour video links will be active for 24 hours:\n'
    for item in video_urls:
        message = message + '\n' + item + '\n\n'

    response = sns.publish(TopicArn='<SNS_TOPIC_ARN>',
                                Subject='Incident Detected',
                                Message=message)

#######################################################
#Run code
overlapped_images = []

print('Starting batch transform job to identfiy obstacles')
batch_job_name = start_batch_transformation("<ML_MODEL_NAME>", 's3://' + output_bucket + '/' + input_prefix,
                        's3://' + output_bucket + '/' + output_prefix)

sagemaker = boto3.client('sagemaker')

while(True):
    response = sagemaker.describe_transform_job(TransformJobName=batch_job_name)
    status = response['TransformJobStatus']
    if status == 'Completed':
        print("Transform job ended with status: " + status)
        break
    if status == 'Failed':
        message = response['FailureReason']
        print('Transform failed with the following error: {}'.format(message))
        raise Exception('Transform job failed')

    print(status)
    time.sleep(30)

print('Looking for potential collisions')
encounters = check_for_collisions(output_bucket, input_prefix, output_bucket, output_prefix)
frames = generate_clip_times(encounters)

#Assumes all files are in MP4 format
orig_file = input_prefix.split("/")[1] + ".MP4"

print('Generating matching video files')
jobs = process_media(origin_bucket, orig_file, output_bucket, frames)

rendered_videos = generate_final_videos(orig_file, output_bucket, jobs)

print('Sending notifications')
send_notifications(rendered_videos)
